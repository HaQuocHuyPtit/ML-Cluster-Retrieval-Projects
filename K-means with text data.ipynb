{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will\n",
    "* Cluster Wikipedia documents using k-means\n",
    "* Explore the role of random initialization on the quality of the clustering\n",
    "* Explore how results differ after changing the number of clusters\n",
    "* Evaluate clustering, both quantitatively and qualitatively\n",
    "\n",
    "When properly executed, clustering uncovers valuable insights from a set of unlabeled documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note to Amazon EC2 users**: To conserve memory, make sure to stop all the other notebooks before running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function # to conform python 2.x print to python 3.x\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with text data, we must first convert the documents into numerical features. As in the first assignment, let's extract TF-IDF features for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wiki = turicreate.SFrame('people_wiki.sframe/')\n",
    "data = pd.read_csv(\"people_wiki.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wiki['tf_idf'] = turicreate.text_analytics.tf_idf(wiki['text'])\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=200000) # , sublinear_tf=True\n",
    "tf_idf = data_matrix = vectorizer.fit_transform(data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remainder of the assignment, we will use sparse matrices. Sparse matrices are matrices that have a small number of nonzero entries. A good data structure for sparse matrices would only store the nonzero entries to save space and speed up computation. SciPy provides a highly-optimized library for sparse matrices. Many matrix operations available for NumPy arrays are also available for SciPy sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above matrix contains a TF-IDF score for each of the 59071 pages in the data set and each of the 200000 most common words found in the whole document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59071, 200000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize all vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the previous assignment, Euclidean distance can be a poor metric of similarity between documents, as it unfairly penalizes long articles. For a reasonable assessment of similarity, we should disregard the length information and use length-agnostic metrics, such as cosine distance.\n",
    "\n",
    "The k-means algorithm does not directly work with cosine distance, so we take an alternative route to remove length information: we normalize all vectors to be unit length. It turns out that Euclidean distance closely mimics cosine distance when all vectors are unit length. In particular, the squared Euclidean distance between any two vectors of length one is directly proportional to their cosine distance.\n",
    "\n",
    "We can prove this as follows. Let $\\mathbf{x}$ and $\\mathbf{y}$ be normalized vectors, i.e. unit vectors, so that $\\|\\mathbf{x}\\|=\\|\\mathbf{y}\\|=1$. Write the squared Euclidean distance as the dot product of $(\\mathbf{x} - \\mathbf{y})$ to itself:\n",
    "\\begin{align*}\n",
    "\\|\\mathbf{x} - \\mathbf{y}\\|^2 &= (\\mathbf{x} - \\mathbf{y})^T(\\mathbf{x} - \\mathbf{y})\\\\\n",
    "                              &= (\\mathbf{x}^T \\mathbf{x}) - 2(\\mathbf{x}^T \\mathbf{y}) + (\\mathbf{y}^T \\mathbf{y})\\\\\n",
    "                              &= \\|\\mathbf{x}\\|^2 - 2(\\mathbf{x}^T \\mathbf{y}) + \\|\\mathbf{y}\\|^2\\\\\n",
    "                              &= 2 - 2(\\mathbf{x}^T \\mathbf{y})\\\\\n",
    "                              &= 2(1 - (\\mathbf{x}^T \\mathbf{y}))\\\\\n",
    "                              &= 2\\left(1 - \\frac{\\mathbf{x}^T \\mathbf{y}}{\\|\\mathbf{x}\\|\\|\\mathbf{y}\\|}\\right)\\\\\n",
    "                              &= 2\\left[\\text{cosine distance}\\right]\n",
    "\\end{align*}\n",
    "\n",
    "This tells us that two **unit vectors** that are close in Euclidean distance are also close in cosine distance. Thus, the k-means algorithm (which naturally uses Euclidean distances) on normalized vectors will produce the same results as clustering using cosine distance as a distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us implement the k-means algorithm. First, we choose an initial set of centroids. A common practice is to choose randomly from the data points.\n",
    "\n",
    "**Note:** We specify a seed here, so that everyone gets the same answer. In practice, we highly recommend to use different seeds every time (for instance, by using the current timestamp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_centroids(data, k, seed=None):\n",
    "    '''Randomly choose k data points as initial centroids'''\n",
    "    if seed is not None: # useful for obtaining consistent results\n",
    "        np.random.seed(seed)\n",
    "    n = data.shape[0] # number of data points\n",
    "        \n",
    "    # Pick K indices from range [0, N).\n",
    "    rand_indices = np.random.randint(0, n, k)\n",
    "    \n",
    "    # Keep centroids as dense format, as many entries will be nonzero due to averaging.\n",
    "    # As long as at least one document in a cluster contains a word,\n",
    "    # it will carry a nonzero weight in the TF-IDF vector of the centroid.\n",
    "    centroids = data[rand_indices,:].toarray()\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initialization, the k-means algorithm iterates between the following two steps:\n",
    "1. Assign each data point to the closest centroid.\n",
    "$$\n",
    "z_i \\gets \\mathrm{argmin}_j \\|\\mu_j - \\mathbf{x}_i\\|^2\n",
    "$$\n",
    "2. Revise centroids as the mean of the assigned data points.\n",
    "$$\n",
    "\\mu_j \\gets \\frac{1}{n_j}\\sum_{i:z_i=j} \\mathbf{x}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pseudocode, we iteratively do the following:\n",
    "```\n",
    "cluster_assignment = assign_clusters(data, centroids)\n",
    "centroids = revise_centroids(data, k, cluster_assignment)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we implement Step 1 of the main k-means loop above? First import `pairwise_distances` function from scikit-learn, which calculates Euclidean distances between rows of given arrays. See [this documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html) for more information.\n",
    "\n",
    "For the sake of demonstration, let's look at documents 100 through 102 as query documents and compute the distances between each of these documents and every other document in the corpus. In the k-means algorithm, we will have to compute pairwise distances between the set of centroids and the set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.34836014 1.28720696]\n",
      " [1.38416243 1.38889899]\n",
      " [1.35115021 1.36364876]\n",
      " ...\n",
      " [1.37559731 1.34862205]\n",
      " [1.36099317 1.24365439]\n",
      " [1.34380117 1.36355488]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Get the TF-IDF vectors for documents 100 through 102.\n",
    "queries = data_matrix[100:102,:]\n",
    "\n",
    "# Compute pairwise distances from every data point to each query vector.\n",
    "dist = pairwise_distances(data_matrix, queries, metric='euclidean')\n",
    "\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More formally, `dist[i,j]` is assigned the distance between the `i`th row of `X` (i.e., `X[i,:]`) and the `j`th row of `Y` (i.e., `Y[j,:]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** For a moment, suppose that we initialize three centroids with the first 3 rows of `tf_idf`. Write code to compute distances from each of the centroids to all data points in `tf_idf`. Then find the distance between row 430 of `tf_idf` and the second centroid and save it to `dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3826776378359966\n"
     ]
    }
   ],
   "source": [
    "three_centroids = data_matrix[0:3,:]\n",
    "dist_three_centroids = pairwise_distances(data_matrix, three_centroids, metric='euclidean')\n",
    "dist = dist_three_centroids[430][1]\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "'''Test cell'''\n",
    "if np.allclose(dist, pairwise_distances(data_matrix[430,:], data_matrix[1,:])):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** Next, given the pairwise distances, we take the minimum of the distances for each data point. Fittingly, NumPy provides an `argmin` function. See [this documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.argmin.html) for details.\n",
    "\n",
    "Read the documentation and write code to produce a 1D array whose i-th entry indicates the centroid that is the closest to the i-th data point. Use the list of distances from the previous checkpoint and save them as `distances`. The value 0 indicates closeness to the first centroid, 1 indicates closeness to the second centroid, and so forth. Save this array as `closest_cluster`.\n",
    "\n",
    "**Hint:** the resulting array should be as long as the number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pairwise_distances(data_matrix, data_matrix[:3,:], metric='euclidean')\n",
    "closest_cluster = np.argmin(distances, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "'''Test cell'''\n",
    "reference = [list(row).index(min(row)) for row in distances]\n",
    "if np.allclose(closest_cluster, reference):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** Let's put these steps together.  First, initialize three centroids with the first 3 rows of `tf_idf`. Then, compute distances from each of the centroids to all data points in `tf_idf`. Finally, use these distance calculations to compute cluster assignments and assign them to `cluster_assignment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = data_matrix[:3,:]\n",
    "distances = pairwise_distances(data_matrix, centroids, metric='euclidean')\n",
    "cluster_assignment = np.argmin(distances, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "if len(cluster_assignment)==59071 and \\\n",
    "   np.array_equal(np.bincount(cluster_assignment), np.array([52863, 177, 6031])):\n",
    "    print('Pass') # count number of data points for each cluster\n",
    "else:\n",
    "    print('Check your code again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fill in the blanks in this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters(data, centroids):\n",
    "    \n",
    "    # Compute distances between each data point and the set of centroids:\n",
    "    # Fill in the blank (RHS only)\n",
    "    distances_from_centroids = pairwise_distances(data, centroids, metric='euclidean')   # YOUR CODE HERE\n",
    "    \n",
    "    # Compute cluster assignments for each data point:\n",
    "    # Fill in the blank (RHS only)\n",
    "    cluster_assignment = np.argmin(distances_from_centroids, axis=1)   # YOUR CODE HERE\n",
    "    \n",
    "    return cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**. For the last time, let us check if Step 1 was implemented correctly. With rows 0, 5, 10, and 15 of `tf_idf` as an initial set of centroids, we assign cluster labels to rows 130, 140, 150, ..., and 220 of `tf_idf`. The resulting cluster labels should be `[0, 0, 2, 0, 3, 0, 2, 0, 0, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 3 0 2 0 0 1]\n",
      "Pass\n"
     ]
    }
   ],
   "source": [
    "test_cluster = assign_clusters(tf_idf[130:230:10], tf_idf[0:20:5])\n",
    "print(test_cluster)\n",
    "if np.allclose(test_cluster, np.array([0, 0, 2, 0, 3, 0, 2, 0, 0, 1])):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revising clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn to Step 2, where we compute the new centroids given the cluster assignments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy and NumPy arrays allow for filtering via Boolean masks. For instance, we filter all data points that are assigned to cluster 0 by writing\n",
    "```\n",
    "data[cluster_assignment==0,:]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop intuition about filtering, let's look at a toy example consisting of 3 data points and 2 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = np.array([[1., 2., 0.],\n",
    "                 [0., 0., 0.],\n",
    "                 [2., 2., 0.]])\n",
    "mock_centroids = np.array([[0.5, 0.5, 0.],\n",
    "                      [0., -0.5, 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign these data points to the closest centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "cluster_assignment = assign_clusters(mock_data, mock_centroids)\n",
    "print(cluster_assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression `cluster_assignment==1` gives a list of Booleans that says whether each data point is assigned to cluster 1 or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise for cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lieu of indices, we can put in the list of Booleans to pick and choose rows. Only the rows that correspond to a `True` entry will be retained.\n",
    "\n",
    "First, let's look at the data points (i.e., their values) assigned to cluster 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_data[cluster_assignment==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense since [0 0 0] is closer to [0 -0.5 0] than to [0.5 0.5 0].\n",
    "\n",
    "Now let's look at the data points assigned to cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 0.],\n",
       "       [2., 2., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_data[cluster_assignment==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this makes sense since these values are each closer to [0.5 0.5 0] than to [0 -0.5 0].\n",
    "\n",
    "Given all the data points in a cluster, it only remains to compute the mean. Use [np.mean()](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.mean.html). By default, the function averages all elements in a 2D array. To compute row-wise or column-wise means, add the `axis` argument. See the linked documentation for details. \n",
    "\n",
    "Use this function to average the data points in cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 2. , 0. ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_data[cluster_assignment==0].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to complete this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_centroids(data, k, cluster_assignment):\n",
    "    new_centroids = []\n",
    "    for i in range(k):\n",
    "        # Select all data points that belong to cluster i. Fill in the blank (RHS only)\n",
    "        member_data_points = data[cluster_assignment==i,:]   # YOUR CODE HERE\n",
    "        # Compute the mean of the data points. Fill in the blank (RHS only)\n",
    "        centroid = member_data_points.mean(axis=0)  # YOUR CODE HERE\n",
    "        \n",
    "        # Convert numpy.matrix type to numpy.ndarray type\n",
    "        centroid = centroid.A1\n",
    "        new_centroids.append(centroid)\n",
    "    new_centroids = np.array(new_centroids)\n",
    "    \n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**. Let's check our Step 2 implementation. Letting rows 0, 10, ..., 90 of `tf_idf` as the data points and the cluster labels `[0, 1, 1, 0, 0, 2, 0, 2, 2, 1]`, we compute the next set of centroids. Each centroid is given by the average of all member data points in corresponding cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "result = revise_centroids(tf_idf[0:100:10], 3, np.array([0, 1, 1, 0, 0, 2, 0, 2, 2, 1]))\n",
    "if np.allclose(result[0], np.mean(tf_idf[[0,30,40,60]].toarray(), axis=0)) and \\\n",
    "   np.allclose(result[1], np.mean(tf_idf[[10,20,90]].toarray(), axis=0))   and \\\n",
    "   np.allclose(result[2], np.mean(tf_idf[[50,70,80]].toarray(), axis=0)):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Assessing convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we tell if the k-means algorithm is converging? We can look at the cluster assignments and see if they stabilize over time. In fact, we'll be running the algorithm until the cluster assignments stop changing at all. To be extra safe, and to assess the clustering performance, we'll be looking at an additional criteria: the sum of all squared distances between data points and centroids. This is defined as\n",
    "$$\n",
    "J(\\mathcal{Z},\\mu) = \\sum_{j=1}^k \\sum_{i:z_i = j} \\|\\mathbf{x}_i - \\mu_j\\|^2.\n",
    "$$\n",
    "The smaller the distances, the more homogeneous the clusters are. In other words, we'd like to have \"tight\" clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_heterogeneity(data, k, centroids, cluster_assignment):\n",
    "    \n",
    "    heterogeneity = 0.0\n",
    "    for i in range(k):\n",
    "        \n",
    "        # Select all data points that belong to cluster i. Fill in the blank (RHS only)\n",
    "        member_data_points = data[cluster_assignment==i, :]\n",
    "        \n",
    "        if member_data_points.shape[0] > 0: # check if i-th cluster is non-empty\n",
    "            # Compute distances from centroid to data points (RHS only)\n",
    "            distances = pairwise_distances(member_data_points, [centroids[i]], metric='euclidean')\n",
    "            squared_distances = distances**2\n",
    "            heterogeneity += np.sum(squared_distances)\n",
    "        \n",
    "    return heterogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the cluster heterogeneity for the 2-cluster example we've been considering based on our current cluster assignments and centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_heterogeneity(mock_data, 2, mock_centroids, cluster_assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining into a single function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the two k-means steps have been implemented, as well as our heterogeneity metric we wish to monitor, it is only a matter of putting these functions together to write a k-means algorithm that\n",
    "\n",
    "* Repeatedly performs Steps 1 and 2\n",
    "* Tracks convergence metrics\n",
    "* Stops if either no assignment changed or we reach a certain number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the blanks\n",
    "def kmeans(data, k, initial_centroids, maxiter, record_heterogeneity=None, verbose=False):\n",
    "    '''This function runs k-means on given data and initial set of centroids.\n",
    "       maxiter: maximum number of iterations to run.\n",
    "       record_heterogeneity: (optional) a list, to store the history of heterogeneity as function of iterations\n",
    "                             if None, do not store the history.\n",
    "       verbose: if True, print how many data points changed their cluster labels in each iteration'''\n",
    "    centroids = initial_centroids[:]\n",
    "    prev_cluster_assignment = None\n",
    "    \n",
    "    for itr in range(maxiter):        \n",
    "        if verbose:\n",
    "            print(itr)\n",
    "        \n",
    "        # 1. Make cluster assignments using nearest centroids\n",
    "        # YOUR CODE HERE\n",
    "        cluster_assignment = assign_clusters(data, centroids)\n",
    "            \n",
    "        # 2. Compute a new centroid for each of the k clusters, averaging all data points assigned to that cluster.\n",
    "        # YOUR CODE HERE\n",
    "        centroids = revise_centroids(data, k, cluster_assignment)\n",
    "            \n",
    "        # Check for convergence: if none of the assignments changed, stop\n",
    "        if prev_cluster_assignment is not None and \\\n",
    "          (prev_cluster_assignment==cluster_assignment).all():\n",
    "            break\n",
    "        \n",
    "        # Print number of new assignments \n",
    "        if prev_cluster_assignment is not None:\n",
    "            num_changed = np.sum(prev_cluster_assignment!=cluster_assignment)\n",
    "            if verbose:\n",
    "                print('    {0:5d} elements changed their cluster assignment.'.format(num_changed))   \n",
    "        \n",
    "        # Record heterogeneity convergence metric\n",
    "        if record_heterogeneity is not None:\n",
    "            # YOUR CODE HERE\n",
    "            score = compute_heterogeneity(data, k, centroids, cluster_assignment)\n",
    "            record_heterogeneity.append(score)\n",
    "        \n",
    "        prev_cluster_assignment = cluster_assignment[:]\n",
    "        \n",
    "    return centroids, cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting convergence metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the above function to plot the convergence metric across iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heterogeneity(heterogeneity, k):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(heterogeneity, linewidth=4)\n",
    "    plt.xlabel('# Iterations')\n",
    "    plt.ylabel('Heterogeneity')\n",
    "    plt.title('Heterogeneity of clustering over time, K={0:d}'.format(k))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider running k-means with K=3 clusters for a maximum of 400 iterations, recording cluster heterogeneity at every step.  Then, let's plot the heterogeneity over iterations using the plotting function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "     2966 elements changed their cluster assignment.\n",
      "2\n",
      "     3627 elements changed their cluster assignment.\n",
      "3\n",
      "     4632 elements changed their cluster assignment.\n",
      "4\n",
      "     3299 elements changed their cluster assignment.\n",
      "5\n",
      "     2359 elements changed their cluster assignment.\n",
      "6\n",
      "     1642 elements changed their cluster assignment.\n",
      "7\n",
      "     1170 elements changed their cluster assignment.\n",
      "8\n",
      "      870 elements changed their cluster assignment.\n",
      "9\n",
      "      683 elements changed their cluster assignment.\n",
      "10\n",
      "      569 elements changed their cluster assignment.\n",
      "11\n",
      "      459 elements changed their cluster assignment.\n",
      "12\n",
      "      365 elements changed their cluster assignment.\n",
      "13\n",
      "      290 elements changed their cluster assignment.\n",
      "14\n",
      "      214 elements changed their cluster assignment.\n",
      "15\n",
      "      163 elements changed their cluster assignment.\n",
      "16\n",
      "      130 elements changed their cluster assignment.\n",
      "17\n",
      "       99 elements changed their cluster assignment.\n",
      "18\n",
      "       74 elements changed their cluster assignment.\n",
      "19\n",
      "       66 elements changed their cluster assignment.\n",
      "20\n",
      "       43 elements changed their cluster assignment.\n",
      "21\n",
      "       39 elements changed their cluster assignment.\n",
      "22\n",
      "       30 elements changed their cluster assignment.\n",
      "23\n",
      "       25 elements changed their cluster assignment.\n",
      "24\n",
      "       22 elements changed their cluster assignment.\n",
      "25\n",
      "       22 elements changed their cluster assignment.\n",
      "26\n",
      "       19 elements changed their cluster assignment.\n",
      "27\n",
      "       20 elements changed their cluster assignment.\n",
      "28\n",
      "       15 elements changed their cluster assignment.\n",
      "29\n",
      "        9 elements changed their cluster assignment.\n",
      "30\n",
      "        8 elements changed their cluster assignment.\n",
      "31\n",
      "        9 elements changed their cluster assignment.\n",
      "32\n",
      "        6 elements changed their cluster assignment.\n",
      "33\n",
      "        3 elements changed their cluster assignment.\n",
      "34\n",
      "        2 elements changed their cluster assignment.\n",
      "35\n",
      "        2 elements changed their cluster assignment.\n",
      "36\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 3\n",
    "heterogeneity = []\n",
    "initial_centroids = get_initial_centroids(tf_idf, k, seed=0)\n",
    "centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, maxiter=400,\n",
    "                                       record_heterogeneity=heterogeneity, verbose=True)\n",
    "plot_heterogeneity(heterogeneity, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. (True/False) The clustering objective (heterogeneity) is non-increasing for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Let's step back from this particular example. If the clustering objective (heterogeneity) would ever increase when running k-means, that would indicate: (choose one)\n",
    "\n",
    "1. k-means algorithm got stuck in a bad local minimum\n",
    "2. There is a bug in the k-means code\n",
    "3. All data points consist of exact duplicates\n",
    "4. Nothing is wrong. The objective should generally go down sooner or later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Which of the cluster contains the greatest number of data points in the end? Hint: Use [`np.bincount()`](http://docs.scipy.org/doc/numpy-1.11.0/reference/generated/numpy.bincount.html) to count occurrences of each cluster label.\n",
    " 1. Cluster #0\n",
    " 2. Cluster #1\n",
    " 3. Cluster #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(cluster_assignment).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beware of local maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One weakness of k-means is that it tends to get stuck in a local minimum. To see this, let us run k-means multiple times, with different initial centroids created using different random seeds.\n",
    "\n",
    "**Note:** Again, in practice, you should set different seeds for every run. We give you a list of seeds for this assignment so that everyone gets the same answer.\n",
    "\n",
    "This may take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=000000, heterogeneity=52497.92614, cluster_distribution=[15987  7572   380  3367  1378  7986   480  6881  6853  8187]\n",
      "seed=020000, heterogeneity=52468.11626, cluster_distribution=[ 9039   720  5060  3645 15785  7632  6453  1840  3847  5050]\n",
      "seed=040000, heterogeneity=52530.96764, cluster_distribution=[ 6649  5929     7  2346  8489  6477  8084  5112  2963 13015]\n",
      "seed=060000, heterogeneity=52408.40408, cluster_distribution=[ 2775  7725  7738  3534  1705 13885  3589  6755  7185  4180]\n",
      "seed=080000, heterogeneity=52377.42070, cluster_distribution=[14624  3163  6792  1697  7064  1982  7534  8117  4488  3610]\n",
      "seed=100000, heterogeneity=52480.06353, cluster_distribution=[ 8037   739  8021  4036  7473  7313  3413 16576  1831  1632]\n",
      "seed=120000, heterogeneity=52507.42954, cluster_distribution=[ 6870  1822  5370  8554  5494  4142    20  8022  5107 13670]\n",
      "340.17422246932983\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "heterogeneity = {}\n",
    "cluster_assignment_dict = {}\n",
    "import time\n",
    "start = time.time()\n",
    "for seed in [0, 20000, 40000, 60000, 80000, 100000, 120000]:\n",
    "    initial_centroids = get_initial_centroids(tf_idf, k, seed)\n",
    "    centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, maxiter=400,\n",
    "                                           record_heterogeneity=None, verbose=False)\n",
    "    # To save time, compute heterogeneity only once in the end\n",
    "    heterogeneity[seed] = compute_heterogeneity(tf_idf, k, centroids, cluster_assignment)\n",
    "\n",
    "    # This is the line we added for the next quiz question\n",
    "    cluster_assignment_dict[seed] = np.bincount(cluster_assignment)\n",
    "    \n",
    "#    print('seed={0:06d}, heterogeneity={1:.5f}'.format(seed, heterogeneity[seed]))\n",
    "    # And this is the modified print statement\n",
    "    print('seed={0:06d}, heterogeneity={1:.5f}, cluster_distribution={2}'.format(seed, heterogeneity[seed], \n",
    "                                           cluster_assignment_dict[seed]))\n",
    "    sys.stdout.flush()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the variation in heterogeneity for different initializations. This indicates that k-means sometimes gets stuck at a bad local minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Another way to capture the effect of changing initialization is to look at the distribution of cluster assignments. Add a line to the code above to compute the size (# of member data points) of clusters for each run of k-means. Look at the size of the largest cluster (most # of member data points) across multiple runs, with seeds 0, 20000, ..., 120000. How much does this measure vary across the runs? What is the minimum and maximum values this quantity takes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One effective way to counter this tendency is to use **k-means++** to provide a smart initialization. This method tries to spread out the initial set of centroids so that they are not too close together. It is known to improve the quality of local optima and lower average runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_initialize(data, k, seed=None):\n",
    "    '''Use k-means++ to initialize a good set of centroids'''\n",
    "    if seed is not None: # useful for obtaining consistent results\n",
    "        np.random.seed(seed)\n",
    "    centroids = np.zeros((k, data.shape[1]))\n",
    "    \n",
    "    # Randomly choose the first centroid.\n",
    "    # Since we have no prior knowledge, choose uniformly at random\n",
    "    idx = np.random.randint(data.shape[0])\n",
    "    centroids[0] = data[idx,:].toarray()\n",
    "    # Compute distances from the first centroid chosen to all the other data points\n",
    "    squared_distances = pairwise_distances(data, centroids[0:1], metric='euclidean').flatten()**2\n",
    "    \n",
    "    for i in range(1, k):\n",
    "        # Choose the next centroid randomly, so that the probability for each data point to be chosen\n",
    "        # is directly proportional to its squared distance from the nearest centroid.\n",
    "        # Roughtly speaking, a new centroid should be as far as from ohter centroids as possible.\n",
    "        idx = np.random.choice(data.shape[0], 1, p=squared_distances/sum(squared_distances))\n",
    "        centroids[i] = data[idx,:].toarray()\n",
    "        # Now compute distances from the centroids to all data points\n",
    "        squared_distances = np.min(pairwise_distances(data, centroids[0:i+1], metric='euclidean')**2,axis=1)\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now rerun k-means with 10 clusters using the same set of seeds, but always using k-means++ to initialize the algorithm.\n",
    "\n",
    "This may take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=000000, heterogeneity=52450.03677\n",
      "seed=020000, heterogeneity=52407.72621\n",
      "seed=040000, heterogeneity=52417.08794\n",
      "seed=060000, heterogeneity=52428.73417\n",
      "seed=080000, heterogeneity=52438.73426\n",
      "seed=100000, heterogeneity=52426.20003\n",
      "seed=120000, heterogeneity=52510.17190\n",
      "463.0376114845276\n"
     ]
    }
   ],
   "source": [
    "# %%time \n",
    "\n",
    "start = time.time()\n",
    "k = 10\n",
    "heterogeneity_smart = {}\n",
    "seeds = [0, 20000, 40000, 60000, 80000, 100000, 120000]\n",
    "for seed in seeds:\n",
    "    initial_centroids = smart_initialize(tf_idf, k, seed)\n",
    "    centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, maxiter=400,\n",
    "                                           record_heterogeneity=None, verbose=False)\n",
    "    # To save time, compute heterogeneity only once in the end\n",
    "    heterogeneity_smart[seed] = compute_heterogeneity(tf_idf, k, centroids, cluster_assignment)\n",
    "    print('seed={0:06d}, heterogeneity={1:.5f}'.format(seed, heterogeneity_smart[seed]))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the set of cluster heterogeneities we got from our 7 restarts of k-means using random initialization compared to the 7 restarts of k-means using k-means++ as a smart initialization.\n",
    "\n",
    "The following code produces a [box plot](http://matplotlib.org/api/pyplot_api.html) for each of these methods, indicating the spread of values produced by each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.boxplot([list(heterogeneity.values()), list(heterogeneity_smart.values())], vert=False)\n",
    "plt.yticks([1, 2], ['k-means', 'k-means++'])\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice from the box plot:\n",
    "* On average, k-means++ produces a better clustering than Random initialization.\n",
    "* Variation in clustering quality is smaller for k-means++."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In general, you should run k-means at least a few times with different initializations and then return the run resulting in the lowest heterogeneity.** Let us write a function that runs k-means multiple times and picks the best run that minimizes heterogeneity. The function accepts an optional list of seed values to be used for the multiple runs; if no such list is provided, the current UTC time is used as seed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_multiple_runs(data, k, maxiter, num_runs, seed_list=None, verbose=False):\n",
    "    heterogeneity = {}\n",
    "    \n",
    "    min_heterogeneity_achieved = float('inf')\n",
    "    best_seed = None\n",
    "    final_centroids = None\n",
    "    final_cluster_assignment = None\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        \n",
    "        # Use UTC time if no seeds are provided \n",
    "        if seed_list is not None: \n",
    "            seed = seed_list[i]\n",
    "            np.random.seed(seed)\n",
    "        else: \n",
    "            seed = int(time.time())\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Use k-means++ initialization\n",
    "        # YOUR CODE HERE\n",
    "        initial_centroids = smart_initialize(data, k, seed)\n",
    "        \n",
    "        # Run k-means\n",
    "        # YOUR CODE HERE\n",
    "        centroids, cluster_assignment = kmeans(data, k, initial_centroids, maxiter=400, record_heteroheneity=None, verbose=False)\n",
    "        \n",
    "        # To save time, compute heterogeneity only once in the end\n",
    "        # YOUR CODE HERE\n",
    "        heterogeneity[seed] = compute_heterogeneity(data, k, centroids, cluster_assignment)\n",
    "        \n",
    "        if verbose:\n",
    "            print('seed={0:06d}, heterogeneity={1:.5f}'.format(seed, heterogeneity[seed]))\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        # if current measurement of heterogeneity is lower than previously seen,\n",
    "        # update the minimum record of heterogeneity.\n",
    "        if heterogeneity[seed] < min_heterogeneity_achieved:\n",
    "            min_heterogeneity_achieved = heterogeneity[seed]\n",
    "            best_seed = seed\n",
    "            final_centroids = centroids\n",
    "            final_cluster_assignment = cluster_assignment\n",
    "    \n",
    "    # Return the centroids and cluster assignments that minimize heterogeneity.\n",
    "    return final_centroids, final_cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are measuring the tightness of the clusters, a higher value of K reduces the possible heterogeneity metric by definition.  For example, if we have N data points and set K=N clusters, then we could have 0 cluster heterogeneity by setting the N centroids equal to the values of the N data points. (Note: Not all runs for larger K will result in lower heterogeneity than a single run with smaller K due to local optima.)  Let's explore this general trend for ourselves by performing the following analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `kmeans_multiple_runs` function to run k-means with five different values of K.  For each K, use k-means++ and multiple runs to pick the best solution.  In what follows, we consider K=2,10,25,50,100 and 7 restarts for each setting.\n",
    "\n",
    "**IMPORTANT: The code block below will take about 10 minutes to finish**\n",
    "\n",
    "In order to speed up the computations, we run them with only one random seed, but for better performance, one should use more seeds and compare the results. If you don't mind running the code for approximately one hour, feel free to uncomment the following line of code below:\n",
    "\n",
    "`seed_list = [0]#, 20000, 40000, 60000, 80000, 100000, 120000]`\n",
    "\n",
    "Side note: In practice, a good implementation of k-means would utilize parallelism to run multiple runs of k-means at once. For an example, see [scikit-learn's KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=000000, heterogeneity=56624.28904\n",
      "seed=000000, heterogeneity=55790.86852\n",
      "seed=000000, heterogeneity=55104.80659\n",
      "seed=000000, heterogeneity=54609.72537\n",
      "seed=000000, heterogeneity=54038.48242\n",
      "Run time: 451.4265069961548\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#import numpy as np \n",
    "\n",
    "start_time = time.time()\n",
    "def plot_k_vs_heterogeneity(k_values, heterogeneity_values):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(k_values, heterogeneity_values, linewidth=4)\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Heterogeneity')\n",
    "    plt.title('K vs. Heterogeneity')\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()\n",
    "\n",
    "centroids = {}\n",
    "cluster_assignment = {}\n",
    "heterogeneity_values = []\n",
    "k_list = [2, 10, 25, 50, 100]\n",
    "seed_list = [0]\n",
    "# Uncomment the following line to run the plot with all the seeds (it may take about an hour to finish).\n",
    "#seed_list = [0, 20000, 40000, 60000, 80000, 100000, 120000]\n",
    "\n",
    "for k in k_list:\n",
    "    heterogeneity = []\n",
    "    centroids[k], cluster_assignment[k] = kmeans_multiple_runs(tf_idf, k, maxiter=400,\n",
    "                                                               num_runs=len(seed_list),                                                               seed_list=seed_list,\n",
    "                                                               verbose=True)\n",
    "    score = compute_heterogeneity(tf_idf, k, centroids[k], cluster_assignment[k])\n",
    "    heterogeneity_values.append(score)\n",
    "print(\"Run time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_k_vs_heterogeneity(k_list, heterogeneity_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot we show that heterogeneity goes down as we increase the number of clusters. Does this mean we should always favor a higher K? **Not at all!** Setting K too high may end up separating data points that are actually pretty alike. At the extreme, we can set individual data points to be their own clusters (K=N) and achieve zero heterogeneity, but separating each data point into its own cluster is hardly a desirable outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
